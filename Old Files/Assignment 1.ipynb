{
 "metadata": {
  "name": "",
  "signature": "sha256:80c1ac9678e618bac49fba131a5e94b6f322b96a6666678cdaac902461f07311"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Assignment 1"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 1. Get Data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data 1:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We first define a function that can download each page of a wikipedia category and save it to a file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "import json\n",
      "import requests\n",
      "import codecs\n",
      "import unicodedata\n",
      "import numpy as np\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def query(request):\n",
      "    request['action'] = 'query'\n",
      "    request['format'] = 'json'\n",
      "    lastContinue = {'continue': ''}\n",
      "    while True:\n",
      "        req = request.copy()\n",
      "        req.update(lastContinue)\n",
      "        result = requests.get('http://en.wikipedia.org/w/api.php',params=req).json()\n",
      "        if 'query' in result: yield result['query']\n",
      "        if 'continue' not in result: break\n",
      "        lastContinue = result['continue']\n",
      "\n",
      "def download_wiki_category(category_name,file_name):\n",
      "    #Category List\n",
      "    content = []\n",
      "    for result in query({'list':'categorymembers','cmtitle':category_name}):\n",
      "        content.append(result)\n",
      "\n",
      "    pageidList = []\n",
      "    titleList = []\n",
      "    p=0\n",
      "    for a in content:\n",
      "        dataList = a['categorymembers']\n",
      "        for d in dataList:\n",
      "            p=p+1\n",
      "            pageidList.append(str(d['pageid']))\n",
      "            titleList.append(d['title'])\n",
      "\n",
      "    #Content\n",
      "    content = []\n",
      "    i=0\n",
      "    while(i<len(pageidList)-50):\n",
      "        ids = ('|' .join(pageidList[i:i+50]))\n",
      "        for result in query({'prop':'revisions','rvprop':'content','pageids':ids}):\n",
      "            content.append(result)\n",
      "        i=i+50\n",
      "    ids = ('|' .join(pageidList[i:]))\n",
      "    for result in query({'prop':'revisions','rvprop':'content','pageids':ids}):\n",
      "        content.append(result)\n",
      "    i = 0\n",
      "    array = []\n",
      "    for con in content:\n",
      "        for ido in pageidList:\n",
      "            array.append(ido)\n",
      "            if ido in con['pages'].keys():\n",
      "                i=i+1\n",
      "\n",
      "    #Parse and save\n",
      "    a=0;\n",
      "    saveDict = dict()\n",
      "    while a<len(pageidList):\n",
      "        for con in content:\n",
      "            if(pageidList[a] in con['pages'].keys()):\n",
      "                saveDict[titleList[a]] = con['pages'][pageidList[a]]\n",
      "                a=a+1\n",
      "    fileObject = codecs.open(file_name,'w','utf-8-sig')\n",
      "\n",
      "    json.dump(saveDict,fileObject)\n",
      "\n",
      "    fileObject.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now use this function to download both the superheroes and supervillains to files on the local HD"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "download_wiki_category('Category:Marvel_Comics_superheroes','MarvelHeroesAssignment.json')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "download_wiki_category('Category:Marvel_Comics_supervillains','MarvelVillainsAssignment.json')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We load the files and divide the data into three exclusive categories. Heroes, Villains, and those that are both"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileObject = codecs.open('MarvelHeroesAssignment.json','r','utf-8-sig')\n",
      "\n",
      "superheroes = json.load(fileObject)\n",
      "\n",
      "fileObject.close()\n",
      "\n",
      "fileObject = codecs.open('MarvelVillainsAssignment.json','r','utf-8-sig')\n",
      "\n",
      "supervillains = json.load(fileObject)\n",
      "\n",
      "fileObject.close()\n",
      "\n",
      "print 'Sum of all characters: '+ str(len(superheroes)+len(supervillains))\n",
      "\n",
      "ambigious = dict()\n",
      "for hero in superheroes:\n",
      "    if hero in supervillains:\n",
      "        ambigious[hero] = superheroes[hero]\n",
      "for gecko in ambigious:\n",
      "    superheroes.pop(gecko)\n",
      "    supervillains.pop(gecko)\n",
      "print 'sum of all characters '+str(len(superheroes)+len(supervillains)+len(ambigious))+'    Equivalent sum from before removal '+str(len(superheroes)+len(supervillains)+len(ambigious)*2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sum of all characters: 2189\n",
        "sum of all characters 2024    Equivalent sum from before removal 2189\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we can see from these sums we have not lost any data in this transformation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data 2:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We begin by using the same query function as before to download the wiki page containing the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title = 'List_of_United_States_cities_by_population'\n",
      "content = []\n",
      "for result in query({'prop':'revisions','rvprop':'content','titles':title}):\n",
      "    content.append(result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We extract the raw data string from the json structure"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data2 = content[0]['pages']['1649321']['revisions'][0]['*']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now extract the names, links, and locations of each city respectively by using string operations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp = data2[data2.index('|-')+2:data2.index('|}')]\n",
      "data2clean = temp[temp.index('|-')+2:]\n",
      "citynames = []\n",
      "citylocations = []\n",
      "citylinks = []\n",
      "for city in data2clean.split('|-'):\n",
      "    temp2 = re.findall(r'\\[\\[(.*?)\\]\\]',city)[0]\n",
      "    if '|' in temp2:\n",
      "        temp3 = temp2[temp2.index('|')+1:]\n",
      "        temp2 = temp2[:temp2.index('|')]\n",
      "    else:\n",
      "        temp3 = temp2\n",
      "    citynames.append(temp3)\n",
      "    citylinks.append(temp2)\n",
      "    citylocations.append(city.split('|')[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As per the assignment we print the first 10 links"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for a in range(10):\n",
      "    print citylinks[a]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New York City\n",
        "Los Angeles\n",
        "Chicago\n",
        "Houston\n",
        "Philadelphia\n",
        "Phoenix, Arizona\n",
        "San Antonio\n",
        "San Diego\n",
        "Dallas\n",
        "San Jose, California\n"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The amount of cities that we have parsed are:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(citynames)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 123,
       "text": [
        "295"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now parse the location strings into N and W value arrays to prepare them for visualization. First we define a function that can parse a single location string."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parseLocation(string):\n",
      "    loc = string.split('N')\n",
      "    N = loc[0].strip()[0:-1]\n",
      "    W = '-'+loc[1].strip()[0:-2]\n",
      "    return [N,W]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 214
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Secondly we use this function on all of the location strings. Note that one of the locations is excluded since the data for this is corrupted"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N_array = []\n",
      "W_array = []\n",
      "for loc in citylocations[:284]+citylocations[285:]:\n",
      "    point = parseLocation(loc)\n",
      "    N_array.append(point[0])\n",
      "    W_array.append(point[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(W_array,N_array,'^')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 218
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The plot very nicely shows a contour of USA"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 2."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Viz 1:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We count the number of characters in each superhero page and visualize it using a histogram"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts = []\n",
      "names = []\n",
      "for hero in superheroes:\n",
      "    counts.append(superheroes[hero]['revisions'][0]['*'].count(''))\n",
      "    names.append(hero)\n",
      "plt.hist(counts,bins=80)\n",
      "plt.ylabel('page count')\n",
      "plt.xlabel('character count')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The plot clearly shows a tendency towards lower values of character count in the pages. The decline in pages with increased character counts seem to almost follow a normal distribution. We can also spot a relatively large group of (maybe) outliers that are 0 or very close. These are probably stub articles and should maybe be culled. We now plot the CDF."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cdfPlot(countArray):\n",
      "    sumDN = 0.\n",
      "    sumN = 0.\n",
      "    for number in countArray:\n",
      "        sumDN = sumDN + number\n",
      "    scounts = []\n",
      "    for number in np.sort(countArray):\n",
      "        sumN = sumN + number\n",
      "        scounts.append(sumN / sumDN)\n",
      "    plt.plot(np.sort(countArray),scounts)\n",
      "    plt.xlabel('character count')\n",
      "    plt.ylabel('P(X)')\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdfPlot(counts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The plot shows a CDF that is arguably reminicant of the CDF of a normal distribution, which further strengthens our claim. \n",
      "\n",
      "We now plot the 10 largest articles in a bar chart"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib.font_manager import FontProperties\n",
      "fontP = FontProperties()\n",
      "fontP.set_size('small')\n",
      "\n",
      "revSorted = np.sort(counts)[::-1]\n",
      "i=0\n",
      "longHeroes = []\n",
      "longNames = []\n",
      "longLBoxes = []\n",
      "colors = ['r','g','b','k','y','m','c','r','g','b']\n",
      "n = 10\n",
      "width = 0.33\n",
      "XGroups = np.arange(1)\n",
      "while i<n:\n",
      "    index = counts.index(revSorted[i])\n",
      "    longNames.append(names[index])\n",
      "    longHeroes.append(plt.bar(XGroups+i*width,counts[index],width/3*2,color=colors[i]))\n",
      "    longLBoxes.append(longHeroes[i][0])\n",
      "    i+=1\n",
      "\n",
      "plt.legend((longLBoxes),(longNames),loc='lower center',ncol = 3,prop=fontP,bbox_to_anchor=(0.54,-0.01))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This list of course includes marvel characters with large fanbases and roles in popular culture. Several are starred in large budget movies. Then again there are also some surprising results"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Viz 2:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now extract the infobox from the hero pages if it exists"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_infoboxes(array):\n",
      "    infoBox = []\n",
      "    for name in array:\n",
      "        result = re.findall(r'({{Superherobox)((.[^}}]|\\n)*.)(}})',array[name]['revisions'][0]['*'])\n",
      "        if not(result==[]):\n",
      "            infoBox.append(result[0][1])\n",
      "    return infoBox\n",
      "infoBoxes = get_infoboxes(superheroes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We extract the debut years from these infoboxes. We discard the data if it is missing and if there are several debut years the earliest is chosen as representative data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "debutBin=[]\n",
      "\n",
      "for info in infoBoxes:\n",
      "    s1 = re.findall(r'debut.*',info)\n",
      "    if not(s1==[]):\n",
      "        years = re.findall(r'[^#](\\d\\d\\d\\d\\b)',s1[0])\n",
      "        if not(years==[]):\n",
      "            debutBin.append(int(min(years)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We visualize this data. We have chosen a histogram of debuts over time, since this is a good representation of how many characters are debuting the different years"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(debutBin,bins=50)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infoBoxes2 = get_infoboxes(supervillains)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "debutBin2=[]\n",
      "\n",
      "for info in infoBoxes2:\n",
      "    s1 = re.findall(r'debut.*',info)\n",
      "    if not(s1==[]):\n",
      "        years = re.findall(r'[^#](\\d\\d\\d\\d\\b)',s1[0])\n",
      "        if not(years==[]):\n",
      "            debutBin2.append(int(min(years)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plt.hist(debutBin2,bins=50)\n",
      "plt.hist([debutBin,debutBin2],bins=35)\n",
      "plt.legend(['Heroes','Villains'])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It would seem from this data that the number of debutant heroes/villains approximate each other over time. This could indicate a trend from before superheroes where had to face off against several different evil villains (the freak of the week concept), toward superheroes having one major enemy that they never can seem to completely vanquish (the nemesis concept).\n",
      "\n",
      "or it could be a coincidence. who knows..."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Viz 3:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We utilize a regex matching scheme to get all of the aliances of each infobox out in as clean a form as possible"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alianceList = dict()\n",
      "\n",
      "for iB in infoBoxes:\n",
      "    s1 = re.findall(r'alliances ?=(.*)',iB)\n",
      "    if not(s1==[]): \n",
      "        s2 = re.split(r'<\\s*br\\s*/>|<\\s*br\\s*>',s1[0])\n",
      "        for group in s2:\n",
      "            s3 = re.findall(r'\\[\\[([^\\]]*)',group)\n",
      "            if not(s3==[]):\n",
      "                s4 = s3[0].split('|')\n",
      "                s4 = s4[len(s4)-1]\n",
      "                if s4 in alianceList:\n",
      "                    alianceList[s4] = alianceList[s4] + 1\n",
      "                else:\n",
      "                    alianceList[s4] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We visualize this as a histogram as well"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(alianceList.values(),bins=50)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can clearly see that most of these 'so-called' aliances have 1 members... This (kind of amusing) result likely stems from the fact that aliances such as \"Stark Industries\", \"the Stark Enterprise\", and \"Stark Enterprises\" are counted seperately"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Viz 4:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}