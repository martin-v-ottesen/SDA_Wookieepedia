%Theory. Which theoretical tools did you use? 
\section{Theory}
To carry out the tasks of analysing this massive dataset we have applied different analysis and visualization techniques.
\subsection{Visualization}
is the discipline of creating diagrams that visually interpret data in such a way that the reader give the reader a higher level of abstraction.
\subsubsection{Histograms}
are a way to graphically represent data distribution of numerical data by dividing it in to non overlapping buckets, the first access represents the intervals and the second access represents the amount of cases that fall into that interval (bucket). In cases where the data is to divers it is customary instead use a logarithmic representation of one or both access.
\subsubsection{Network Graph}
are graphs used to represent relations between data, an example could be a family tree, social interactions or other relationships.
\subsection{Machine Learning}
is the discipline of collecting data and finding its principle components and by the process of supervised or unsupervised learning classify or regress the data.
\subsubsection{Bag of Words}
this is a model used for processing of natural language, in which you generate a vocabulary that can be used for document classification. 
\subsubsection{Decision Trees}
is a tree like graph that stems from a root of the entire dataset and then on the basis of calculated "decisions" gets subdivided into new subsets, this goes on until the data is classified.
\subsubsection{Multinomial bayes' classifier} is a probabilistic classification method which is biassed upon Bayes' theorem. Using a multinomial model on samples thereby creating a feature vector used to classify data with a value from zero to one on each for each class we wish to compare with (the sum of there classifies values is one).